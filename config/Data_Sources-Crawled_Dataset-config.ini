#这个文件是新闻网站爬虫的配置文件
#它定义了爬虫的基本配置，包括新闻网站的URL、关键词、爬虫映射、最大页面数等

[NewsSites]
tencent_news = https://news.qq.com/
thepaper_news = https://www.thepaper.cn
xinhua_news = https://so.news.cn
people_news = https://www.people.com.cn
36kr_news = https://36kr.com
#澎湃新闻

[Keywords]
tencent_news_keywords = 深度伪造,AI恶意软件开发,AI算法歧视,AI违规内容,AI错误与误导信息,AI与社会不平等,AI诈骗
thepaper_news_keywords = 深度伪造,AI恶意软件开发,AI算法歧视,AI违规内容,AI错误与误导信息,AI与社会不平等,AI诈骗
xinhua_news_keywords = 深度伪造,AI恶意软件开发,AI算法歧视,AI违规内容,AI错误与误导信息,AI与社会不平等,AI诈骗
people_news_keywords = 深度伪造,AI恶意软件开发,AI算法歧视,AI违规内容,AI错误与误导信息,AI与社会不平等,AI诈骗
36kr_news_keywords = 深度伪造,AI恶意软件开发,AI算法歧视,AI违规内容,AI错误与误导信息,AI与社会不平等,AI诈骗
[CrawlerMapping]
tencent_news = crawlers.tencent_news_crawler.scrape_tencent_news
thepaper_news = crawlers.thepaper_news_crawler.scrape_thepaper_news
xinhua_news = crawlers.xinhua_news_crawler.scrape_xinhua_news
people_news = crawlers.people_news_crawler.run_scraper
36kr_news = crawlers.kr36_news_crawler.run_scraper
[MaxPages]
tencent_news_max_pages = 15
thepaper_news_max_pages = 10
xinhua_news_max_pages = 15
people_news_max_pages = 15
36kr_news_max_pages = 15
[Manual]
# 手动模式下是否自动上传
auto_upload = false

[TestMode]
# 是否启用测试模式
enabled = true
# 测试模式下是否自动上传
auto_upload = false
# 指定要测试的站点名称
test_site = thepaper_news

[AutoCrawler]
# 是否启用自动爬取
enabled = false
# 定时执行时间
schedule_time = 02:00
# 定时执行日期
schedule_day = monday

[API]
base_url = https://api.example.com
# 注意修改为实际的api_url

# 可以继续添加更多新闻网站，格式为：网站名称 = URL
#以澎湃新闻为例 不是翻页而是下滑出现更多内容的新闻网站中的MaxPages意思即为下拉次数